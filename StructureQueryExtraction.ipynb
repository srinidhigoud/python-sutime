{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/bert_tf/lib/python3.7/site-packages/jpype/_core.py:210: UserWarning: \n",
      "-------------------------------------------------------------------------------\n",
      "Deprecated: convertStrings was not specified when starting the JVM. The default\n",
      "behavior in JPype will be False starting in JPype 0.8. The recommended setting\n",
      "for new code is convertStrings=False.  The legacy value of True was assumed for\n",
      "this session. If you are a user of an application that reported this warning,\n",
      "please file a ticket with the developer.\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "  \"\"\")\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from sutime import SUTime\n",
    "jar_files = os.path.join(os.getcwd(), 'jars')\n",
    "sutime = SUTime(jars=jar_files, mark_time_ranges=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"end\": 38,\n",
      "        \"start\": 14,\n",
      "        \"text\": \"from 2pm to 3pm tomorrow\",\n",
      "        \"type\": \"DATE\",\n",
      "        \"value\": \"2019-08-02 INTERSECT (T14:00,T15:00,PT1H)\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "test_case = u'I need a desk from 2pm to 3pm tomorrow'\n",
    "print(json.dumps(sutime.parse(test_case), sort_keys=True, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sent = \"Give me the objects that were healthy last tuesday and unhealthy tomorrow\"\n",
    "test_sent = \" \".join(test_sent.strip().split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import en_core_web_sm\n",
    "from spacy import displacy\n",
    "from textblob import TextBlob\n",
    "from textblob.sentiments import NaiveBayesAnalyzer\n",
    "nlp = spacy.load('../Bert_NER/Data/')\n",
    "nlp2 = spacy.load('en_core_web_sm')\n",
    "doc2 = nlp2(test_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: ['Give me the objects that were healthy last tuesday and unhealthy tomorrow']\n",
      "After: ['Give me the objects that were healthy last tuesday and', 'unhealthy tomorrow']\n"
     ]
    }
   ],
   "source": [
    "print(\"Before:\", [sent.text for sent in doc2.sents])\n",
    "\n",
    "def set_custom_boundaries(doc):\n",
    "    for token in doc[:-1]:\n",
    "        if token.text == \"and\" or token.text == \"but\" or token.text == \"or\" or token.text == \",\" :\n",
    "            doc[token.i+1].is_sent_start = True\n",
    "    return doc\n",
    "\n",
    "nlp2.add_pipe(set_custom_boundaries, before=\"parser\")\n",
    "doc2 = nlp2(test_sent)\n",
    "print(\"After:\", [sent.text for sent in doc2.sents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = {\"ACI_OBJECT\":'#E0FFFF',\"OPER\":'#FFB6C1',\"MODF\":'#FFFACD',\"HEALTH\":'#E6E6FA'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"end\": 50,\n",
      "        \"start\": 38,\n",
      "        \"text\": \"last tuesday\",\n",
      "        \"timex-value\": \"2019-07-23\",\n",
      "        \"type\": \"DATE\",\n",
      "        \"value\": \"2019-07-23\"\n",
      "    }\n",
      "]\n",
      "{'object': ['objects'], 'time': ['2019-07-23'], 'oper': [], 'health-score': [100]}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Give me the \n",
       "<mark class=\"entity\" style=\"background: #E0FFFF; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    objects\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">aci_object</span>\n",
       "</mark>\n",
       " that were \n",
       "<mark class=\"entity\" style=\"background: #E6E6FA; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    healthy\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">health</span>\n",
       "</mark>\n",
       " last tuesday and</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"end\": 18,\n",
      "        \"start\": 10,\n",
      "        \"text\": \"tomorrow\",\n",
      "        \"timex-value\": \"2019-08-02\",\n",
      "        \"type\": \"DATE\",\n",
      "        \"value\": \"2019-08-02\"\n",
      "    }\n",
      "]\n",
      "{'object': [], 'time': ['2019-08-02'], 'oper': [], 'health-score': [0]}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #E6E6FA; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    unhealthy\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">health</span>\n",
       "</mark>\n",
       " tomorrow</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for sent in doc2.sents:\n",
    "    query = {\"object\":[],\"time\":[],\"oper\":[],\"health-score\":[]}\n",
    "    doc = nlp(str(sent))\n",
    "    h_sent = \"\"\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_==\"health\":\n",
    "            h_sent += ent.text + \" \"\n",
    "        elif ent.label_==\"aci_object\":\n",
    "            query[\"object\"].append(ent.text)\n",
    "        elif ent.label_==\"oper\":\n",
    "            query[\"oper\"].append(ent.text)\n",
    "    h_sent = h_sent[:-1]\n",
    "    zen = TextBlob(h_sent, analyzer=NaiveBayesAnalyzer())\n",
    "    score = 0\n",
    "    if h_sent:\n",
    "        if zen.sentiment.classification=='neg':\n",
    "            query[\"health-score\"].append(0)\n",
    "#             print('Score is: ',0)\n",
    "        else:\n",
    "            query[\"health-score\"].append(100)\n",
    "            score = 100\n",
    "#             print('Score is: ',100)\n",
    "    su_t = sutime.parse(str(sent))\n",
    "    for it in su_t:\n",
    "        query['time'].append(it['value'])\n",
    "        print(json.dumps(su_t, sort_keys=True, indent=4))\n",
    "#         print(it['value'])\n",
    "        print(query)\n",
    "    queries.append(query)\n",
    "    \n",
    "    displacy.render(doc, jupyter=True, style='ent',options={'colors':cls})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for i,sent in enumerate(h_sents):\n",
    "#     zen = TextBlob(sent, analyzer=NaiveBayesAnalyzer())\n",
    "#     score = 0\n",
    "#     if sent:\n",
    "#         if zen.sentiment.classification=='neg':\n",
    "#             queries[i][\"health-score\"].append(0)\n",
    "#             print('Score is: ',0)\n",
    "#         else:\n",
    "#             queries[i][\"health-score\"].append(100)\n",
    "#             score = 100\n",
    "#             print('Score is: ',100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import flair\n",
    "# flair_sentiment = flair.models.TextClassifier.load('en-sentiment')\n",
    "# s = flair.data.Sentence(sent)\n",
    "# flair_sentiment.predict(s)\n",
    "# total_sentiment = s.labels\n",
    "# total_sentiment\n",
    "\n",
    "# if sent:\n",
    "#     if total_sentiment=='neg':\n",
    "#         query[\"health-score\"].append(0)\n",
    "#         print('Score is: ',0)\n",
    "#     else:\n",
    "#         query[\"health-score\"].append(100)\n",
    "#         score = 100\n",
    "#         print('Score is: ',100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i,sent in enumerate(doc2.sents):\n",
    "#     su_t = sutime.parse(str(sent))\n",
    "#     for it in su_t:\n",
    "#         queries[i]['time'].append(it['value'])\n",
    "#         print(it['value'])\n",
    "# #     print(json.dumps(su_t, sort_keys=True, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(test_sent+\"\\n\")\n",
    "# displacy.render(doc, jupyter=True, style='ent',options={'colors':cls})\n",
    "# print('\\n')\n",
    "# print(queries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"ed8c7debd1924a0e91077a1407082a48-0\" class=\"displacy\" width=\"400\" height=\"224.5\" direction=\"ltr\" style=\"max-width: none; height: 224.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">unhealthy</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">tomorrow</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ed8c7debd1924a0e91077a1407082a48-0-0\" stroke-width=\"2px\" d=\"M70,89.5 C70,2.0 225.0,2.0 225.0,89.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ed8c7debd1924a0e91077a1407082a48-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,91.5 L62,79.5 78,79.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, jupyter=True, style='dep',options={'colors':cls})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training!\n",
      "successfully loaded: models_compressed.pkl\n",
      "done training!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import autocomplete\n",
    "# import pandas as pd\n",
    "# from autocomplete import models\n",
    "# data = pd.read_csv(\"../Bert_NER/Data/training_dataset_2.csv\", encoding=\"latin1\").fillna(method=\"ffill\")\n",
    "# data = \" \".join(data['Word'].tolist())\n",
    "# models.train_models(data)\n",
    "autocomplete.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('virtual', 134),\n",
       " ('vrf', 58),\n",
       " ('vrfs', 47),\n",
       " ('vzbrcp', 46),\n",
       " ('vpc', 45),\n",
       " ('vpcs', 40)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autocomplete.predict('the','v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:bert_tf]",
   "language": "python",
   "name": "conda-env-bert_tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
